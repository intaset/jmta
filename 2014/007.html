<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="robots" content="noarchive">
<meta name="description" content="The Volume 1, Issue 1 published for JMTA Journal.">
<meta name="keywords" content="avestia, publishing, journals, papers, science, renewable energy">
<title>JMTA -  Echolocating with Ultrasound: A Usability Analysis</title>

<meta name="handheldfriendly" content="true">
<meta name="mobileoptimized" content="240">
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> 
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<link href="../css/avestia.css" rel="stylesheet">
<link href='http://fonts.googleapis.com/css?family=Lato:100,300,400,700,900,100italic,300italic,400italic,700italic,900italic|Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
<link rel="shortcut icon" href="../img/icon.ico" type="image/x-icon">
<!--[if IE-9]><html lang="en" class="ie9"><![endif]-->

<script src="../js/modernizr.custom.63321.js"></script>
<script type="text/javascript" src="../mostvisited.js"></script> 
<script type="text/javascript" src="../mostvisitedExt.js"></script> 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-68628727-1', 'auto');
  ga('send', 'pageview');

</script>
<script>
  (function() {
    var cx = '016656741306535874023:f_iiykae6ri';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') +
        '//cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
</head>
<body class="loading">
<nav id="slide-menu">
  <h1>Avestia Publishing</h1>
  <ul>
    <li><a href="about">About Us</a></li>
    <li><a href="ethics">Ethics in Publishing</a></li>
    <li><a href="openaccess">Open Access</a></li>
    <li><a href="editor">Become a Reviewer or an Editor</a></li>
    <li><a href="publishing">Your Publishing Needs</a></li>
    <li><a href="proceedings">Conference Proceedings</a></li>
    <li><a href="news">Latest News</a></li>
    <li><a href="guidelines">Author Guidelines</a></li>
    <li><a href="journals">Journals</a></li>
    <li><a href="http://amss.avestia.com/">Submission</a></li>
    <li><a href="copyright">Copyright</a></li>
    <li><a href="contact">Contact Us</a></li>
  </ul>
</nav>

<div id="content">
  <div class="desktop">
      <div class="cbp-af-header">
  <div class="cbp-af-inner">
    <a href="/"><img src="../img/logo.svg" class="flex-logo" alt="Avestia Publishing"></a>

    <div class="nav1">
      <nav>
        <a href="/">Home</a>
        <a href="http://amss.avestia.com/">Submission</a>
        <a href="journals">Journals</a>
        <a href="ethics">Ethics in Publishing</a>
        <a href="guidelines">Author Guidelines</a>
      </nav>
    </div>

    <div class="search-menu">
      <div class="menu-trigger-1"><p class="menu">MENU</p></div><br>
      <gcse:searchbox-only resultsUrl="results"></gcse:searchbox-only>
    </div>

    <div class="nav2">
      <nav>
        <a href="/">Home</a>
        <a href="http://amss.avestia.com/">Submission</a>
        <a href="journals">Journals</a>
        <a href="ethics">Ethics in Publishing</a>
        <a href="guidelines">Author Guidelines</a>
      </nav>
    </div>
  </div>
</div>
  </div>

  <header>
    <div class="mobile">
      <div class="cbp-af-header">
  <div class="cbp-af-inner">
    <div class="unit unit-s-3-4 unit-m-1-3 unit-l-1-3">
          <a href="/"><img src="../img/logo.svg" class="flex-logo" alt="Avestia Publishing"></a>
      </div>
      <div class="unit unit-s-1-3 unit-m-2-3 unit-m-2-3-1 unit-l-2-3">
          <div class="menu-trigger"></div>
      </div>
  </div>
</div>
      <div class="bg">
        <gcse:searchbox-only resultsUrl="results"></gcse:searchbox-only>
      </div>
    </div> <!--Mobile -->
  </header>

  <div class="j-header-article">
  <div class="name">
    <h1>Journal of Multimedia Theory and Applications (JMTA)<br>
    <p class="body">ISSN: 2368-5956</p></h1>
    <div class="oalink">
    <a href="/openaccess" target="blank" title="Avestia's Open Access">
          <img src="../img/j-oa.png" border="0" onmouseover="this.src='../img/j-oa-hover.png'" onmouseout="this.src='../img/j-oa.png'" class="j-oa">
    </a>
  </div>
  </div>
</div>

  <div role="navigation" class="navbar navbar-default">
  <ul>
    <li><a href="">Journal Home</a></li>
    <li><a href="aims">Aims & Scopes</a></li>
    <li><a href="fee">Publishing Fee</a></li>
    <li><a href="board">Editorial Board</a></li>
    <li><button data-target=".navbar-collapse" data-toggle="collapse" class="navbar-toggle" type="button">Volumes</button></li>
    <li><a href="contact">Contact Us</a></li>
  </ul>
  <div class="navbar-collapse collapse">
    <ul class="nav navbar-nav">
      <li><a href="volume1">Volume 1</a></li>
      <li><a href="current">Current Volume</a></li>
    </ul>
  </div><!--/.nav-collapse -->
</div>

<div class="grid">
<div class="unit unit-s-1 unit-m-1 unit-l-1">
  <div class="main-content j-home">
    <div class="unit unit-s-1 unit-s-1-2 unit-m-1-2 unit-l-1-2">
      <p class="body">Volume 1, Year 2014 - Pages 60-69<br>
      DOI: 10.11159/jmta.2014.007</p>
    </div>

    <div class="unit unit-s-1 unit-s-1-2 unit-m-1-2 unit-l-1-2 a-link">
        <a href="PDF/007.pdf" class="body-link" class="body-link">View PDF (Full-text)</a><br>
      <a href="#references" class="body-link">Linked References</a>
    </div>

    <h3 class="center">Echolocating with Ultrasound: A Usability Analysis</h3>

    <p class="body-bold center">Alan Deacon<sup>1</sup>, T. Claire Davies<sup>1</sup>, Shane Pinder<sup>2</sup></p>

    <p class="body center"><sup>1</sup>University of Auckland, Mechanical Engineering, Private Bag 92019, Auckland, 1142, New Zealand<br>
c.davies@auckland.ac.nz; ajdeaco@hotmail.com<br>

<sup>2</sup>Manukau Institute of Technology, Manukau Engineering, Auckland, New Zealand<br>
sdpinder@gmail.com</p>

    <p class="body"><b>Abstract</b> - <i>Individuals
who are totally blind do not have access to visual stimuli, thus one must
account for other relationships with nature that provide information to enable
effective locomotion and travel. Typically a primary mobility aid such as a
long, white cane or a guide dog are used, but these are unable to detect
obstacles that are not ground based including tree branches, windows that open
outward and wall mounted bookcases. A device known as the AUDEO (audification
of ultrasound for the detection of environmental echoes) has been developed as
a means to providing information about obstacles above waist height to people
with visual impairment. This is expected to be used in addition to a primary
mobility aid, but intended to give the individual more confidence in travelling
in unknown environments where head high obstacles may exist.</i></p>

    <p class="body"><b><i>Keywords:</i></b> Audification,
Mobility devices, Visual impairment, Obstacle avoidance, Vertical localisation.</p>

    <p class="body">&copy; Copyright 2015 Authors This is an Open Access article published under the <a href="http://creativecommons.org/licenses/by/3.0" class="body-link" target="_blank" class="body-link">Creative Commons Attribution License terms</a>. Unrestricted use, distribution, and reproduction in any medium are permitted, provided the original work is properly cited.</p>

    <p class="body">Date Received: 2013-09-17 <Br>
Date Accepted: 2014-02-05 <br>
Date Published: 2014-02-24</p>

  <div class="border"></div>

  <div class="indent">
<h4>1. Introduction</h4>


<p class="body">Motivated
by the large number of visually impaired and blind people worldwide, and the
related prevalence of injuries caused by head-level obstacles, there is a need
for advancement in the design of navigation and secondary assistive devices.
Furthermore, due to the aging trend within the world s population [1] and the
correlation between age and vision impairment, these issues are likely to
increase in the coming years.</p>

<p class="body">A survey of 300 legally blind or functionally
blind individuals from the United States of America was conducted by Manduchi
and Kurniawan in 2011 and investigated the frequency, nature, and causes of
head-level and fall accidents [2].
Of the 300 respondents, over half acknowledged that they had at least one
head-level accident a year, with over 12% experiencing mishaps more often than
once a month. The respondents were also questioned about the environments in
which these accidents occurred. Eighty-six percent reported outdoor collisions
mainly with tree branches, but others included contact with signs and poles.
The indoor accidents tended to occur as a result of bumping into shelves,
tables, and staircases, or doors and cabinets being left ajar.</p>

<p class="body">The accidents are often serious with 23% resulting
in some medical consequence, 60% of those requiring professional medical
assistance for stitches, staples, or dental treatment for broken teeth. The
accidents had lingering effects on many people with 43% suggesting that they
had changed their walking habits due to an accident, usually walking slower or
protecting their head with a raised arm as they walk, and 26% feeling less
confident in independent travel. Some respondents commented that they avoid
certain areas or require sighted companions to accompany them.</p>

<p class="body">Falls are another significant area of risk. Only
8% of the respondents in the same study said that they had never experienced a
trip resulting in a falling incident [2].
Over 35% said that they had such occurrences happen more than once a year.
Those who were blind (with at most light perception) as opposed to legally
blind (who meet the criteria to be legally blind, but can perceive shapes) were
twice as likely to be involved in a tripping or head-level injury. A
correlation also existed between those walking into objects and those having
falls.</p>

<p class="body">Manduchi and Kuriawan's study also showed how
uncomfortable many of the individuals were in unfamiliar environments [2].
Of the individuals surveyed 40% would only travel unfamiliar routes once per
week (if any) and 22% would not leave their residence more than 5 times a week.
It was discovered that the respondents that used guide dogs tended to travel
more that those using long canes. This suggests that a good aid defines the
comfort zone and the likelihood of adventure.</p>



<h4>2. Related Work</h4>

<p class="body">John
Neuhoff described the detection and recognition of sound as "the result of a
complex interaction of physics, physiology, sensation, perception and
cognition" [3]. The focus of this research was to
maintain the majority of these interactions naturally while incorporating the
physical design of an assistive technology to be used by individuals with
visual impairment as a secondary mobility device.</p>

<p class="body">Several
sonar devices have been developed to help increase the preview distance before
physically contacting obstacles, but few have gained acceptance. These devices
are used in addition to a long white cane and are termed secondary mobility
devices [4-6]. Sonar devices
include the Trisensor and Sonic Pathfinder and convert echo information into
audible information. </p>

<p class="body">A
significant advantage of sonar relative to that of echolocation is that it may
not be as sensitive to the factors that affect audible echolocation. For
instance, the quality of the signal can be improved by increasing the
transmitter power. Since other individuals cannot hear the signal, an increase
in the power does not affect others. In an auditory situation, absorption
results in a lower sound pressure level, making it too soft to hear. If the
transmit power is increased at ultrasound, absorption still occurs and
decreases the signal strength, but ultrasound receivers are also more sensitive
than the ears at picking up high frequency reflections. As a result,
characteristic textures can more easily be detected with ultrasound than within
audition. Ambient noise that influences interpretation of sounds in the
auditory range does not affect the reflected signals in the ultrasound domain.
Sounds that may not be heard in the auditory range will still generate a
reflected ultrasound signal. </p>

<p class="body">The
basic premise of the current sonar secondary mobility devices is that
ultrasound information is transmitted by a wide-angle beam ultrasound
transducer and received by other transducers. Information from the backscatter
of ultrasonic waves is transmitted to the ears. </p>

<p class="body">There
are two devices that are fairly common when referring to sonar secondary aids.
These are the KASPA developed by Dr. Leslie Kay [4, 5] and the Sonic
Pathfinder developed by Dr. Anthony Heyes [6]. Additional
focus on these systems is further presented.</p>

<p class="body">The
Trisensor, later termed the Sonic Guide and more recently the KASPA, was
developed by Kay in 1962 as a "wide-angle binaural" ultrasonic aid [4]. A
transmitter and two receivers are mounted on the nosepiece of a pair of
glasses. Information from the backscatter of ultrasonic waves is transmitted to
the ears binaurally using sonification of the signal such that interaural
intensity differences represent directional differences, and pitch indicates
the distance to an obstacle. This device is a continuous scanning device that
provides tones about all obstacles in the environment regardless of motion of
the user or look direction. As the sonified signal is not developed to minimise
masking, other aspects of the surroundings cannot easily be heard. An
individual using this device cannot readily communicate with those around,
limiting the device solely to independent travel situations. </p>

<p class="body">The
Trisensor only portrays information using interaural intensity differences [7]. This system does not consider the
effects of head related transfer functions and interaural time differences, nor
does it portray sufficient information about the spatial environment to be able
to effectively identify slopes and curvature, even by an individual with
considerable practice. </p>

<p class="body">The
Sonic Pathfinder developed by Heyes in 1984 is currently one of the least expensive
available secondary detection systems. This device is a pulse echo digital
device that uses a musical scale to represent obstacles in the path of the user
[6]. This device
uses two transmitter transducers and three receivers to cover the field of
view. It prioritises the obstacle immediately in front of the user and does
not provide any additional information until the obstacle is beyond the field
of view. The Sonic Pathfinder uses earcons in the sense that as a person
approaches an obstacle, the tone increases or decreases along an Ionic scale
(the most common musical scale). Although this is acceptable for the obstacle
nearest the individual, it does not represent the spatial environment as a
whole. As the distance from the obstacle in the "frame of reference"
decreases, the pitch of the tone decreases. </p>



<h4>3.
Identification of System Requirements</h4>

<p class="body">The AUDEO attempts to address the issues
experienced with the aforementioned devices. Usability testing with the AUDEO
has been conducted with blindfolded, sighted participants under anechoic
conditions and has focused on sound localisation [8],
distance approximation, and aperture passage [9].
The first two tests were designed to evaluate a participant s ability to
accurately interpret the auditory information in a way that could be used to
locate the position, both direction and distance, of an environmental obstacle
relative to a user. The aperture passage experiment demonstrated how the method
of echolocation could be used in everyday situations. </p>

<p class="body">There were however, several usability issues
identified during this testing. First, the device was larger and
more bulky than would be intended in a final design. It was hypothesised that
different, or more accurate results, might be obtained if the individuals were
not constrained by the size of the prototype [8,9]. Secondly, the orientations
of receivers were limited to two directions. These two orientations were
supposed to be representative of the same direction as the eyes and the same
direction as the ears. Although both appeared effective in the judgement of
distance and the ability to avoid apertures, it became apparent during the
testing of localisation that in fact the ears have a complex structure that
neither faces outward nor forward. Looking toward a sound not only allows an
individual to use vision to more precisely locate it, but also brings that
sound into the area which can most easily be interpreted, that which allows
similar information in both ears, or the area immediately in front of the
individual. The second hypothesis was that a device that can capitalise on the
shape of the ear may result in better localisation ability and be more usable.</p>

<p class="body">The purpose of this paper
is to detail the further development process of the AUDEO device to make it
both smaller and better able to capitalise on the shape of the ear, thus
increasing vertical localisation and usability. Hearing
aids have been manufactured in various guises since the 1800 s; initially bulky
ear horns, the hearing aid of today can be entirely contained within the ear
canal of a user [10]. There is a tremendous amount of research
and trial and error development on which to draw. The earpiece design for the
AUDEO technology incorporated solutions from earlier hearing aid designs that
have overcome issues of diminished localisation and occlusion.</p>


<h4>4.
Background and Theory</h4>

<p class="body">For
individuals with visual impairment, localisation is often achieved by
interpreting sounds within the environment. The AUDEO device capitalizes on
echolocation, Doppler shifts and down conversion of the ultrasound signals to
provide useful auditory information to the user. </p>


<p class="subhead">4.1. Echolocation</p>

<p class="body">Echolocation
uses the sound localisation principle. Sound reflects off environmental
obstacles allowing for directional detection. There are two forms of
echolocation. The first, known as active echolocation, results when an
individual provides a sound to the environment that reflects. Another form of
echolocation is passive echolocation in which the individual uses environmental
sounds to detect obstacles within an environment. For example, some shops have
music playing. This music will reflect and create a soundscape interpretable to
the individual with visual impairment. </p>

<p class="body">If
an observer makes a sound, the reflected signals will return to that observer
in the form of echoes. Distance can be determined between an observer and the
reflector by the difference in time between the initiation of the sound and the
return of its reflection (see Figure 1). </p>

<p class="body">A
sound wave travelling through air will move at approximately 340.29ms<sup>-1</sup> <span id="footnote1">*</span>.
Therefore the distance between an object and a sound source can be calculated
as:</p>

<center><div class="widetable">
<table style="border:0">
 <tr>
  <td style="padding:5px" align="right"><img src="007_files/image001.png"></td>
  <td style="padding:5px" align="left"><img src="007_files/image002.png"></td>
 </tr>
 <tr>
  <td style="padding:5px"></td>
  <td style="padding:5px" align="left"><img src="007_files/image003.png"></td>
 </tr>
 </table>
 </div></center>
 
<p class="body">The direction of the reflection, as
determined by sound localisation, defines the directional origin of the object.
</p>

<figure>
<img src="007_files/image004.png" class="article-img">

<figcaption>
Figure 1. Image showing
waves during reflection of sound</figcaption>
</figure>


<p class="subhead">4.2. Doppler Effect</p>

<p class="body">The
Doppler Effect describes a change in the frequency of a signal as a result of
the relative motion between the transmitter (or a reflector) and the observer.
A sound source moving toward an observer results in the waves immediately in
front compressing relative to the emitted waves while those behind expand. This
can be related as follows: </p>

<div class="equation">
<img src="007_files/image005.png" class="eqn">
<div class="eqn-number">(1)</div>
</div>


<p class="body">with c being the velocity of waves in the
medium (air), v<sub>r </sub>representing the velocity of the receiver relative
to the medium while v<sub>s</sub> represents the velocity of the source
relative to the medium. </p>

<p class="body">Although
the AUDEO capitalizes on echolocation in the sense that the transmitted signal
reflects off environmental obstacles, it differs from active echolocation as it
provides a continuous ultrasonic signal rather than a discrete chirp. The
relative difference between an observed and emitted frequency at ultrasound is
much larger than in the auditory range, allowing the AUDEO device to better
present environmental reflections than a typical auditory echolocation process.
</p>

<p class="subhead">4.3.
Doppler Shift</p>

<p class="body">The
AUDEO device transforms the received high frequency sound reflections to an
audible range via the process of direct down-conversion [11]. Using a 40 kHz sampling rate equal to
that of the transmitted signal, the sound is intentionally aliased so the final
output is the difference between the transmitted signal and the received
signal. The difference between the two signals is caused by a Doppler shift
that is created by the relative speed of the receiver and the object from which
the echoes are reflecting. </p>

<p class="body">At
40 kHz the signals that are transmitted and received are well beyond the normal
human hearing range (as well as beyond the detection of dogs) which allows the
device to be used in environments in which clicking or clapping of the hands is
deemed socially unacceptable. </p>



<p class="subhead">4.4. Down Conversion</p>

<p class="body">The
Doppler shifted, received signal described above is then down sampled by the
intentional aliasing of the signal. Aliasing occurs when the sampling frequency
is less than twice that of the frequency being sampled (Nyquist Criterion [12]). For many applications, such as the
recording and playback of music, aliasing is avoided. Digital audio has a
sample rate of 44.1 kHz or greater to allow frequencies below 22 kHz (those
within the human hearing range) to be produced unaltered [13]. </p>

<p class="body">However,
in the case of the AUDEO, the signal is intentionally aliased as follows. The
resultant wave produced from an aliased sine signal will be equal to the
difference between the initial signal and the sampling rate. This has been
demonstrated in the example below (figure 7). A 200Hz sine signal (blue) is
sampled at a rate of ~267Hz, as marked by the crosses. The resultant wave form
(red) is the difference between the signal rate and sample rate (267 Hz – 200
Hz=) ~67Hz. </p>

<figure>
<img src="007_files/image006.jpg" class="article-img">

<figcaption>
Figure 2. Aliasing of a 200Hz Sine wave, with a 267Hz Sample Rate [Blue: Initial Signal, Red: Aliased Signal, Cross: Sample points]</figcaption>
</figure>


<p class="body">The
AUDEO device receives the Doppler shifted signal and samples it at the 40 kHz
transmission frequency. The resultant waveform is equal to the difference in
frequency from the transmitted and received signals. This produces a signal
within the audible range that is amplified and then provided to the user via
speakers. </p>

<h4>5. AUDEO
System Design</h4>

<p class="body">A
miniaturised AUDEO PCB was created to research the possibility of reducing the
size of the transmitter circuitry. The PCB propagated an ultrasound wave that
was created by an ATMega168 microcontroller (Atmel ATMega168) timed with a
crystal oscillator. The microcontroller created a 4 V<sub>pk-pk </sub>square
wave at a frequency of 40 kHz. This wave was propagated with a ST100 ultrasound
transmitter. The audible range of the AUDEO device under these conditions was
limited to approximately 1.0 m. Additional strategies to increase the range
were then explored.</p>



<p class="subhead">5.1. Wave Manipulation</p>

<p class="body">The
purpose of wave manipulation was to increase the possible range of the
transmitted sound signal. First, the square wave was converted to a sine wave
as it is a more efficient means of power transmission. Second the sine wave was
amplified to increase the power and therefore the transmission range of the
signal.</p>

<p class="body">In
the first stage of the conversion, the square wave from the microcontroller is
passed to a difference amplifier with a gain of two. The square wave signal is
compared to a constant 2V signal produced by a voltage divider from the power
source. The use of a difference amplifier was used to centre the output voltage
about 0 V, this way the peak-peak voltage was made larger before clipping
occurred.</p>

<p class="body">The
amplifier was chosen due to its low slew rate. By setting the gain of the
amplifier to 2x when the square wave switched between its high and low state,
the output wave did not have enough time to reach the peak voltage because of
the high frequency. The resultant output was instead a triangle wave with a
frequency of 40 kHz and amplitude of 6 V<sub>pk-pk</sub>.</p>

<p class="body">The
6-V<sub>pk-pk</sub> wave was then passed to a low-pass passive filter. Low-pass
filters are created using a resistor in series to a signal and capacitor in
parallel. A low-pass filter allows for frequencies below the set value to pass
while high frequencies are removed. This frequency value is proportional to the
capacitor and resistor. </p>


<div class="equation">
<img src="007_files/image007.png" class="eqn">
<div class="eqn-number">(2)</div>
</div>

<p class="body">As
a triangle wave is combination of multiple harmonic frequencies starting from
its fundamental frequency, by removing the frequencies above 40 kHz the
resultant wave form was a pure 40 kHz sine wave.</p>

<p class="body">Finally
the sine wave produced by the low-pass filter is passed to a second amplifier.
The second amplifier has a significantly higher slew rate and does not alter
the shape of the waveform but simply amplifies it. </p>

<p class="subhead">5.2. Sample and Hold</p>

<p class="body">The
down-sampling of the received ultrasound signal allows conversion of the
ultrasound into a signal range at the audible level. This was achieved using a
sample-and-hold integrated circuit (IC). A sample-and-hold IC operates by
sampling a signal at an input rate defined by a clock input. Once the clock is
triggered the IC takes the value of the signal at the time then this value is
held until the negative clock edge at which time the voltage drops to ground</p>



<p class="subhead">5.3. Information Processing</p>

<p class="body">The
last stage is information processing. Following the sample-and-hold is a
resistor-capacitor (RC) low-pass filter. The purpose of this filtering stage is
to remove noise from the signal before passing it to the speaker. In this case,
a resistor of 4&#937; is used in combination with a capacitor of 22&micro;F. This can
be explained through the calculations below that relate to the velocity of the
user s movement. </p>


<div class="equation">
<img src="007_files/image007.png" class="eqn">
<div class="eqn-number">(3)</div>
</div>

<div class="equation">
<img src="007_files/image008.png" class="eqn">
<div class="eqn-number">(4)</div>
</div>

<div class="equation">
<img src="007_files/image009.png" class="eqn">
<div class="eqn-number">(5)</div>
</div>

<div class="equation">
<img src="007_files/image010.png" class="eqn">
<div class="eqn-number">(6)</div>
</div>

<p class="body">The
frequency of 1800 Hz, for instance, represents a relative velocity of</p>

<div class="equation">
<img src="007_files/image011.png" class="eqn">
<div class="eqn-number">(7)</div>
</div>

<div class="equation">
<img src="007_files/image012.png" class="eqn">
<div class="eqn-number">(8)</div>
</div>

<div class="equation">
<img src="007_files/image013.png" class="eqn">
<div class="eqn-number">(9)</div>
</div>

<div class="equation">
<img src="007_files/image014.png" class="eqn">
<div class="eqn-number">(10)</div>
</div>


<p class="body">As
the sound wave travels from the observer then back again the relative velocity
is half of this value. </p>

<div class="equation">
<img src="007_files/image015.png" class="eqn">
<div class="eqn-number">(11)</div>
</div>


<p class="body">Under
the controlled environment in which an individual typically walks, this
velocity is not likely to be exceeded. Therefore any noise above this frequency
can be removed. </p>

<h4>6. Receiver Design</h4>

<p class="body">Previous
designs had the receivers placed externally on a headset (Figure 3 a and b:
Sony Dynamic Stereo Headphones MDR-V250). One of the issues identified by the earlier
testing of the device was that the shape of the ear and its reflections
contribute heavily to the ability of a person to localise sound vertically. It
was decided that an in-the-ear design was required.</p>

<figure>
<img src="007_files/image016.jpg" class="article-img">

<figcaption>
Figure 3. Iterations of the AUDEO device receivers</figcaption>
</figure>


<p class="subhead">6.1. Down-conversion Circuitry</p>

<p class="body">The
down-conversion circuitry had originally been placed within the earpiece of the
headset. For down-conversion to occur, an operational amplifier (OpAmp) was
required to amplify the received signal and a sample-and-hold IC to sample the
signal down to audible frequency. These components also required a printed
circuit board (PCB) on which to mount the components. To power the
down-conversion circuitry the OpAmp requires +9-V and -9-V power supplies for
its positive and negative rail respectively and a ground signal to create an
inverting amplifier. The sample-and-hold IC also requires the 9-V power supply,
a ground reference, and a 40-kHz clock signal to be used as a sample rate. To
transfer the power and signal lines five separate wires are required between
the ear piece and the main transmitter circuit board (mounted in the headset). </p>

<p class="body">The
design was enhanced by moving the down-conversion and amplification circuitry
to the main transmitter PCB. This reduced the number of lines to connect the
earpiece with the transmitter to three. The modified version required only a
ground line, an output line from the ultrasound receiver to the amplification
circuitry, and an input line for the 'in ear  speaker from the down-conversion
circuitry. Rather than having individual OpAmps for each of the ear pieces
these can be combined in a single dual- or quad-OpAmp IC, thereby reducing the
number of parts. Furthermore, space was saved in the ear piece by not requiring
the PCB or electronic components. </p>



<p class="subhead">6.2. Earpiece Design</p>

<p class="body">Typically,
hearing aids are either custom designed for the user s specific ear shape and
size or the user is fitted based on a range of pre-designed moulds [4]. The principal goal for individual fitting
of hearing aids is to ensure comfort and to enhance communication skills [15]. However for the usability testing of the
AUDEO device it was deemed that the time taken to individually fit each
participant was not practical. The ear piece was instead designed to be
flexible in its use so that a range of participants would be able to
comfortably and efficiently use the device. </p>

<p class="body">There
were three key requirements for design of an ear piece. The ear piece was to:</p>

<ul>
  <li>hold firmly in place a speaker
and ultrasound receiver; </li>
  <li>be flexible and fit any number
of users, and; </li>

  <li>be able to be cleaned and
reused.</li>
</ul>

<p class="body">After
an iterative design process, the solution was to use headphone ear buds.
Phillips ErgoFit headphones provide a range of rubber ear bud sizes. The rubber
ear buds fit firmly around the speaker (Knowles Acoustics) and allow the unit
to fit firmly and comfortably within the ear. Additionally, the Ergofit range
allows the ear buds to be fitted to the individual user and also can be removed
and cleaned between test participants (Figure 3 c and d).</p>



<p class="subhead">6.3. Maintaining Audible Range Sound</p>

<p class="body">The
AUDEO hearing piece fits tightly in the ear of the user. Sound can only enter
the ear through the speakers. The speakers are fed by the sound taken in from
the ultrasound receiver. The bandwidth of the ultrasound receiver is narrow and
will only receive sound close to the 40 kHz frequency; this means that the
normal audible range (i.e. sound frequencies of 20-20kHz) is not picked up. To
resolve this issue a secondary receiver could be used to provide the lower
audible range information. Simply by using a lower frequency receiver and
summing this input with the down sampled AUDEO feedback, it should allow
audible communicated information to be retained.</p>

<p class="body">Alternatively,
vents could be used to allow this sound to travel into the ear. Vents have been
used in ITC hearing aids to reduce the occlusion effect [16]; however they could in this instance
create a path through which audible information could travel into the ear
canal. </p>



<h4>7. UsabilityTesting- VerticalLocalisation</h4>

<p class="body">The
miniaturized device was designed to increase usability as well as to increase
localisation ability. The aforementioned tests [8, 9] had identified
that vertical localisation was an issue with the previous version of the
device. It was now important to test the ability of human participants to
localize using this new version of the device. The purpose of the usability
testing was to compare the ITE version of the device, with the previous version
of the device (out of the ear or OTE). </p>


<p class="subhead">7.1. Participants</p>

<p class="body">A
group of 10 adults ages between 20-30 years volunteered for this study. All participants
were in good health, without visual impairment and with no physical
disabilities that would affect their capacity to complete this study. None of
the participants had previous experience with the AUDEO device prior to the
testing period. Participants gave written, informed consent to this study in
accordance with the guidelines of the University of Auckland Human Ethics
Committee. The participants were blindfolded during testing to simulate vision
loss. There is evidence that blindfolded participants can quickly learn to
compensate for loss of sight [17]. </p>



<p class="subhead">7.2. Experimental Protocol </p>

<p class="body">This
experiment followed a similar process that Davies et al. used to assess a
person s ability to localise sound in earlier experiments [8]. A participant was seated in front of an
array of speakers placed vertically. A white noise was produced and the
participants were asked to identify the source speaker.</p>



<p class="subhead">7.3. Test Procedure</p>

<p class="body">The
participants were first tested with the ITE placement of the receivers. To
demonstrate how the system worked, sounds from each of the five transmitters
were played once, in sequence from top to bottom, and they were clearly
identified by the tester. The participant was then blindfolded. A random
transmitter produced an encrypted white noise signal for the duration of two
seconds. The participant attempted to identify the source of the transmission.
The participant was then told which transmitter had actually been used. </p>

<p class="body">Feedback
was given to the participant to simulate the learning process that an end user
may undertake when learning device use. A group of 25 signals were produced and
played semi-randomly through the transmitters so that each of the transmitters
was used five times. </p>



<p class="subhead">7.4. Variables Assessed</p>

<p class="subhead"><i>7.4.1. AUDEO Receiver
Placement</i></p>

<p class="body">We
hypothesised that the placement of the receivers in the ear would allow for
better localisation than the out of the ear version as vertical sound
localisation should be aided by the ear pinna when the receivers were placed
inside the ear. </p>



<p class="subhead"><i>7.4.2. Transmitter
Position</i></p>

<p class="body">An
experimental rig was created for testing that placed five ultrasound
transmitters in a one meter arc at angles of 15<sup>o </sup>with each of the
transmitters facing inwards towards the centroid of the arc where the
participant was seated. The transmitters were numbered 1 to 5.</p>


<p class="subhead"><i>7.4.3. Correct
Predictions, F<sub>(c)</sub></i></p>

<p class="body">The
participant s ability to detect a sound source in the vertical plane was
compared with percentage values. First was the percentage of correct guesses.
This considered the occurrences when the participant selected the correct
source of the signal.</p>

<p class="subhead"><i>7.4.4. Above or Below
Predictions, F<sub>(ab)</sub></i></p>

<p class="body">A
measure was taken to determine whether a participant was able to differentiate
between sound sources above or below them. This value was calculated by
identification of transmitters 1, 2 (above) or 4, 5 (below). For example, if
transmitter 2 was used to produce a signal, a prediction of 1 or 2 would be
considered correct as both values are above centre, whereas values 3, 4 or 5
would be considered incorrect. Similarly if transmitter 5 was used, a
prediction of 4, 5 would be correct, whereas 1, 2 and again 3 would be
considered incorrect.</p>



<p class="subhead">7.5. Statistical Analysis</p>

<p class="body">Analyses
of Variance (ANOVA) were used to identify the underlying population differences
under the various conditions. TUKEY post-hoc analysis was performed to report
any specific differences. </p>

<figure>
<img src="007_files/image017.jpg" class="article-img">

<figcaption>
Figure 4. A scatter
plot showing correct position estimates</figcaption>
</figure>


<figure>
<img src="007_files/image018.jpg" class="article-img">

<figcaption>
Figure 5.
Scatter Plot of Correct Predictions (condition above/below) Comparing Position
of Receivers</figcaption>
</figure>

<p class="body">An
analysis of variance showed that there was no evidence that the placement of
the receiver influences the participant s ability to correctly identify the
actual location of the sound source F<sub>(c)</sub> =1.414 (p &gt; 0.12) (Fig.<sub>
</sub>4). Of the ten participants, eight scored higher while operating the ITE
compared to the OTE, one received identical results, only one of the ten
participants performance decreased using the ITE design. This participant
population scored on average ~7.2% higher for the ITE design than the OTE
during testing. </p>

<p class="body">When
judging whether a sound has come from above or below the participant, there is
evidence to suggest that the percentage of correct predictions is higher for
participants when they are using the ITE placement of the receivers when
compared to the OTE F<sub>(ab)</sub>=2.5796, (p&lt;0.05) (Fig 5). Observations
showed that, of the ten participants, nine scored higher while operating the
ITE. We are 95% confident that the ITE design will result in an increase of up
to 19.2%.</p>


<h4>8. Discussion</h4>

<p class="body">From
research into vertical sound localisation, it was believed that the ear pinna
had a significant influence on a person s ability to differentiate sounds in a
vertical plane. It was hypothesised that the ITE earpiece would retain more of
the spectral cues provided from the pinna than the original OTE earpiece and in
turn would result in improved performance during the vertical sound source
localisation experiment.</p>

<p class="body">The
evidence from the vertical localisation testing, however, was not significant
enough to suggest a difference in population averages between the ITE and OTE
earpieces under the correct prediction condition. Despite this, the ITE design
demonstrated better results for 80% of the participants from the limited
population. Overall from the 10 participants, the ITE design performed better
than the OTE design by a range of 37.2% to 30%. There was evidence, however,
that the broader vertical understanding from the AUDEO device is improved with
the ITE design. Both of these two conditions are, however, significantly better
than what would be expected from a random selection of the five transmitters.
This is attributed to the directionality of the ultrasound receivers, each
receiver would decrease in sensitivity by 6dB per 30<sup>o</sup> diversion from
the centre, and this would mean that there may be slight difference in
amplitude between the higher and lower transmitters and those positioned in the
middle.</p>

<p class="body">When
instructing the participants on how to undertake the vertical localisation
section of the test, they were asked to name which of the five transmitters had
produced the white noise signal. They were not instructed as to whether or not
they were allowed to move their head vertically. Interestingly, of the 10
participants tested, only one attempted to move the head in an attempt to gain
more information. This participant moved his head in a scanning pattern from
top to bottom. However, this did not appear to benefit the individual who
managed only 32% correct for both the ITE and OTE designs.</p>



<h4>9. Conclusion</h4>

<p class="body">The
earpieces were designed to test the hypothesis that the placement of the
receivers would improve a user s ability to localise vertical sounds by
retaining the natural spectral cues generated by the ear pinna. Miniaturising
the earpiece, from the large over ear earphones to smaller ear buds, allowed
the receivers to be positioned much deeper inside the ear. As a result of the
redesign there was a noticeable improvement in the vertical localisation ability
of the participants using the ITE when compared to the results of the previous
OTE style. The evidence suggests an improvement for the broad understanding of
what is above or below them. Further testing with the new version of the device
is warranted to evaluate whether better localisation may be achieved.</p>

<h4 id="references">References</h4>
<div class="ref">
<p class="body">[1] Haub, C. <i>World Population Aging: Clocks Illustrate
Growth in Population Under Age 5 and Over Age 65</i>. 2011 [cited 2013 28
January]; Available from: <a href="http://www.prb.org/Articles/2011/agingpopulationclocks.aspx" target="_blank">View Article</a></p>

<p class="body">[2]
Manduchi, R. and S. Kurniawan, <i>Mobility-Related Accidents Experienced by
People with Visual Impairment.</i> Association for Education and Rehabilititoin
Journal, 2011. <b>4</b>(2): p. 11. <a href="http://users.soe.ucsc.edu/~manduchi/papers/MobilityAccidents.pdf" target="_blank">View Article</a></p>

<p class="body">[3]
Neuhoff, J.G., <i>Ecological Psychoacoustics</i>. 2004, New York: Academic
Press. <a href="http://books.google.ca/books?id=_2YQTg76OAEC&dq=Ecological+Psychoacoustics&hl=en&sa=X&ei=21tFVNvYBNemyASq-YK4Dw&redir_esc=y" target="_blank">View Book</a></p>

<p class="body">[4]
Kay, L., <i>Auditory perception of objects by blind persons, using a
bioacoustic high resolution air sonar.</i> Journal of the Acoustical Society of
America, 2000. <b>107</b>(6): p. 3266-3275. <a href="http://dx.doi.org/10.1121/1.429399" target="_blank">View Article</a></p>

<p class="body">[5]
Kay, L., <i>Bioacoustic spatial perception by humans: a controlled laboratory
measurement of spatial resolution without distal cues.</i> J Acoust Soc Am,
2001. <b>109</b>(2): p. 803-8. <a href="http://dx.doi.org/10.1121/1.1336138" target="_blank">View Article</a></p>

<p class="body">[6]
Heyes, A.D., <i>The Sonic Pathfinder - a New Electronic Travel Aid.</i> Journal
of Visual Impairment &amp; Blindness, 1984. <b>78</b>(5): p. 200-202. <a href="http://eric.ed.gov/?id=EJ301318" target="_blank">View Article</a></p>

<p class="body">[7]
Easton, R.D., <i>Inherent problems of attempts to apply sonar and vibrotactile
sensory aid technology to the perceptual needs of the blind.</i> Optom Vis Sci,
1992. <b>69</b>(1): p. 3-14. <a href="http://journals.lww.com/optvissci/abstract/1992/01000/inherent_problems_of_attempts_to_apply_sonar_and.2.aspx" target="_blank">View Article</a></p>

<p class="body">[8]
Davies, T.C., Pinder, S. D., Dodd, G., Burns, C. M., <i>Where did that sound
come from? Comparing the ability to localise using audification and audition.</i>
Disabil Rehabil Assist Technol, 2012. <b>7</b>(2): p. 130-8. <a href="http://dx.doi.org/10.3109/17483107.2011.602172" target="_blank">View Article</a></p>

<p class="body">[9]
Davies, T.C., S.D. Pinder, and C.M. Burns, <i>What's that sound? Distance
determination and aperture passage from ultrasound echoes.</i> Disabil Rehabil
Assist Technol, 2011. <b>6</b>(6): p. 500-10. <a href="http://dx.doi.org/10.3109/17483107.2010.542569" target="_blank">View Article</a></p>

<p class="body">[10]
Vohringer, C.G., <i>CIC Hearing Aid</i>. 2006: United States. <a href="http://www.google.com/patents/US20080137891" target="_blank">View Article</a></p>

<p class="body">[11]
Davies, T.C. and S. Pinder, <i>Exploring Direct Downconversion of Ultrasound
for Human Echolocation.</i> 2007. <a href="http://dx.doi.org/10.1145/1278960.1278967" target="_blank">View Article</a></p>

<p class="body">[12]
Shannon, C.E., <i>Communication in the presence of noise.</i> Institute of
Radio Engineers, 1949. <b>37</b>(1): p. 10-21. <a href="http://dx.doi.org/10.1109/JRPROC.1949.232969" target="_blank">View Article</a></p>

<p class="body">[13]
Self, D., <i>Audio Engineering Explained</i>, ed. T.F. US. 2012. <a href="http://books.google.ca/books?hl=en&lr=&id=WzYm1hGnCn4C&oi=fnd&pg=PT1&dq=Audio+Engineering+Explained&ots=-WG0m4Q31o&sig=njDwgVv7CrLW_xahn0ljGVwyUTY#v=onepage&q&f=false" target="_blank">View Book</a></p>

<p class="body">[14]
New Zealand Audiological Society Inc, <i>Hearing Aid Selection Fitting and
Follow-Up</i>. 2008. <a href="http://www.audiology.org.nz/userfiles/file/pdf/Hr%20Aid%20Slction.pdf" target="_blank">View Article</a></p>

<p class="body">[15]
Sickel, K., Baloch, S., Bubnik, V., Melkisetoglu, R., Azernikov, S., Fang, T.,
Hornegger, J., <i>Semi-Automatic Manufacturing of Customized Hearing Aids Using
a Feature Driven Rule-based Framework.</i> Proceedings of the Vision, Modeling,
and Visualization Workshop 2009 (Braunschweig, Germany November 16-18, 2009),
2009: p. 305-312. <a href="http://icg.rz.tu-bs.de/downloads/papers/sic09.pdf" target="_blank">View Article</a></p>

<p class="body">[16]
Ross, M. <i>The &quot;Occulsion Effect&quot; - What it is and What to Do About
it</i>. 2004 9 September 2011 [cited 2013 29 Jan]; Available from: <a href="http://www.hearingresearch.org/ross/hearing_loss/the_occlusion_effect.php" target="_blank">View Article</a></p>

<p class="body">[17]
Loomis, J.M., Klatzky, R. L., Golledge, R. G., Cicinelli, J. G., Pellegrino, J.
W., Fry, P. A., <i>Nonvisual Navigation by Blind and Sighted - Assessment of
Path Integration Ability.</i> Journal of Experimental Psychology-General, 1993.
<b>122</b>(1): p. 73-91. <a href="http://dx.doi.org/10.1037/0096-3445.122.1.73" target="_blank">View Article</a></p>

 <p class="body"><a href="#footnote1">*</a> The speed of sound is variable
relative to humidity and temperature</p>

<p class="body"><a href="#footnote2">**</a> The time is divided by 2 as the
total distance the sound wave travels from the source, to the object then back
to the source (Figure 1).</p>
</div> <!--REF -->
  </div> <!--INDENT -->

  </div> <!--Main Content -->
</div>
</div>

  <footer>
<div class="grid">
  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer">
      <ul class="footer-links">
        <li><a href="/" class="body-link">Avestia Publishing</a></li>
        <li><a href="journals" class="body-link">Journals</a></li>
        <li><script>var refURL = window.location.protocol + "//" + window.location.host + window.location.pathname; document.write('<a href="http://international-aset.com/feedback/?refURL=' + refURL+'">Feedback</a>');</script></li>
        <li><a href="terms" class="body-link">Terms of Use</a></li>
        <li><a href="sitemap" class="body-link">Sitemap</a></li>
      </ul>
    </div>
  </div>

  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer">
      <p class="body">
        Avestia Publishing,<br>
        International ASET Inc.<br>
        Unit 417, 1376 Bank St.<br>
        Ottawa, ON, Canada, K1H 7Y3<br>
        +1 613-695-3040<br>
        <a href="mailto:info@avestia.com" class="body-link">info@avestia.com</a>
      </p>
    </div>
  </div>

  <div class="unit unit-s-1 unit-s-1-3 unit-m-1-3 unit-l-1-3">
    <div class="unit-spacer social">
    <form class="subscribe" action="../subscribe.php" method="post">
            <span id="sprytextfield2"><input name="email" type="text" id="email" value="Join our mailing list"
              onblur="if (this.value == '') {this.value = 'Join our mailing list';}"
        onfocus="if (this.value == 'Join our mailing list') {this.value = '';}" ></span>
      <input type="submit" name="submit" value="Submit" class="form_button" />
        </form>
        
      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://www.facebook.com/pages/International-Academy-of-Science-Engineering-and-Technology/207827708283" target="blank" title="International ASET Inc. Facebook Page">
          <img src="../img/fb.png" border="0" onmouseover="this.src='../img/fb-hover.png'" onmouseout="this.src='../img/fb.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://twitter.com/ASET_INC" target="blank" title="International ASET Inc. Twitter">
          <img src="../img/twitter.png" border="0" onmouseover="this.src='../img/twitter-hover.png'" onmouseout="this.src='../img/twitter.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://www.linkedin.com/company/1169039" target="blank" title="International ASET Inc. LinkedIn">
          <img src="../img/linkedin.png" border="0" onmouseover="this.src='../img/linkedin-hover.png'" onmouseout="this.src='../img/linkedin.png'">
        </a>
      </div>

      <div class="unit unit-s-1-1 unit-m-1-1 unit-l-1-1">
        <a href="https://plus.google.com/u/0/+International-aset/posts" target="blank" title="International ASET Inc. Google+ Page">
          <img src="../img/google.png" border="0" onmouseover="this.src='../img/google-hover.png'" onmouseout="this.src='../img/google.png'">
        </a>
      </div>

      <p class="body">&copy; Copyright 2015, International ASET Inc. - All Rights Reserved.</p>
    </div>
  </div>

</div>
</footer>
</div>

 <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"></script>
    <script src="../js/cbpAnimatedHeader.min.js"></script>
    <script src="../js/SpryValidationSelect.js" type="text/javascript"></script>

    <script src="../js/SpryValidationTextField.js" type="text/javascript"></script>

    <script src="../js/SpryValidationConfirm.js" type="text/javascript"></script>

    <script src="../js/SpryValidationCheckbox.js" type="text/javascript"></script>
    <script src="../js/SpryValidationTextarea.js" type="text/javascript"></script>

<script src="../js/classie.js"></script>
<script src="../js/jquery.easing.js"></script>
<script src="../js/jquery.mousewheel.js"></script>
<script defer src="../js/demo.js"></script>
<script type="text/javascript" src="../css/animate.min.css"></script>
<script type="text/javascript" src="../js/jnav.js"></script>

<script type="text/javascript">
<!--
var sprytextfield1 = new Spry.Widget.ValidationTextField("sprytextfield1", "none");
var sprytextfield2 = new Spry.Widget.ValidationTextField("sprytextfield2", "email");
var sprytextfield3 = new Spry.Widget.ValidationTextField("sprytextfield3");
var sprytextfield4 = new Spry.Widget.ValidationTextField("sprytextfield4");
var spryselect2 = new Spry.Widget.ValidationSelect("spryselect2", {invalidValue:"-1"});
var sprytextarea1 = new Spry.Widget.ValidationTextarea("sprytextarea1");
var sprytextfield5 = new Spry.Widget.ValidationTextField("sprytextfield5");
var sprytextfield6 = new Spry.Widget.ValidationTextField("sprytextfield6");
//-->
</script>

    <script type="text/javascript">
/*
  Slidemenu
*/
(function() {
  var $body = document.body
  , $menu_trigger = $body.getElementsByClassName('menu-trigger')[0];

  if ( typeof $menu_trigger !== 'undefined' ) {
    $menu_trigger.addEventListener('click', function() {
      $body.className = ( $body.className == 'menu-active' )? '' : 'menu-active';
    });
  }

}).call(this);
</script>

<script type="text/javascript">
/*
  Slidemenu
*/
(function() {
  var $body = document.body
  , $menu_trigger = $body.getElementsByClassName('menu-trigger-1')[0];

  if ( typeof $menu_trigger !== 'undefined' ) {
    $menu_trigger.addEventListener('click', function() {
      $body.className = ( $body.className == 'menu-active' )? '' : 'menu-active';
    });
  }

}).call(this);
</script>
</body>
</html>